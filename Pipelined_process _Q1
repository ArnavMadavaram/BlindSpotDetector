#step 1: Preprocessing

import cv2
import numpy as np
import glob
import os

#rgb Process
def load_and_preprocess_rgb(file_path, img_size=(256, 256)):
    img = cv2.imread(file_path)
    img = cv2.resize(img, img_size)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype("float32") / 255.0
    return img

#Depth Proces
def load_and_preprocess_depth(file_path, img_size=(256,256), max_depth=3000.0):
    if file_path.endswith('.npy'):
        depth = np.load(file_path)
    else:
        depth = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)
    depth = cv2.resize(depth, img_size)
    depth = depth.astype("float32") / max_depth
    depth = np.expand_dims(depth, axis=-1)
    return depth

#SS Process
def load_and_preprocess_semantic(file_path, img_size=(256,256)):
    if file_path.endswith('.npy'):
        seg = np.load(file_path)
    else:
        seg = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
    seg = cv2.resize(seg, img_size, interpolation=cv2.INTER_NEAREST)
    seg = seg.astype("int32")
    seg = np.expand_dims(seg, axis=-1)
    return seg

#Radar Process
def load_and_preprocess_radar_for_frame(frame_filename, radar_df, img_size=(256,256), max_radar_depth=3000.0):
    base = os.path.splitext(frame_filename)[0]   # "rgb_285379"
    num_str = base.split('_')[-1]                  # "285379"
    frame_num = int(num_str)
    
    # Filter DataFrame for this frame
    frame_data = radar_df[radar_df['frame'] == frame_num]
    if len(frame_data) == 0:
        radar_value = 0.0
    else:
        radar_value = frame_data['depth'].mean()
    normalized_value = radar_value / max_radar_depth
    # Create a constant image of size img_size with the normalized radar value
    radar_img = np.full(img_size, normalized_value, dtype="float32")
    radar_img = np.expand_dims(radar_img, axis=-1)
    return radar_img


#STEP 2:: Fuse using Deep Learning into a tensor
def create_fused_tensor(rgb_img, depth_img, radar_img, semantic_img):
   # For raw semantic labels:
   #RGB: 3 channels Depth: 1 channel Radar: 1 channel Semantic: 1 channel Total: 6 channels.
    fused_tensor = np.concatenate([rgb_img, depth_img, radar_img, semantic_img], axis=-1)
    return fused_tensor



